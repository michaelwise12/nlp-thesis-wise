# nlp-thesis-wise
## Code Repository for Honors Thesis Project
### Author: Michael Wise
### Advisor: Eitel Laur√≠a
### Marist College, Fall 2022

Note that this thesis is an extention of my [Honors By Contract project](https://github.com/michaelwise12/hbc-wise).

---

This project focuses on the topic of finding the best technique for performing sentiment analysis on Twitter data. We explore the practicality of using social media, like Twitter, as a mode of identifying sentiment of the general population during a specific time period. In traditional NLP, sentiment analysis comes with many problems, including procedures for collecting/scraping data, preprocessing it, and the dilemma of dealing with unlabeled text. In combination with a lexicon called [VADER](https://github.com/cjhutto/vaderSentiment), we aim to show the best methodology for deriving a sentiment score and assigning feelings and emotions to tweets and messages using both "old-school" and "new-school" techniques, with the latter referring to state-of-the-art transformers. While showing the differences between old-school techniques (stemming, stop words) and new-school techniques (transformer tokenization & self-attention) for preprocessing, we describe a paradigm for what we think is the most effective procedure for processing social media data. Through various validation techniques, we address the most up to date and innovative transformer encoders like BERT, RoBERTa, ALBERT, and ELECTRA to determine what is the best at processing natural language and predicting sentiment from that data in comparison to and old-school multinomial Naive Bayes classifier trained using a bag of words approach. For our purposes, RoBERTa performed the best with 89% accuracy on unseen tweets, while ELECTRA showcased its ability to fine-tune the quickest without losing too much accuracy at 87%. Tranformers are shown to perform miles better than old-school methods with little to no preprocessing or hyperparameter tuning required, as the multinomial NB was only able to achieve 80% accuracy. We showcase the current state of NLP, focusing on Tweets related to the Ukraine vs. Russia Crisis, along with its already shown potential to illustrate the emotional state of our world over time.

The repo contains the Juptyer notebook for all of the analysis. The `.csv` that was scraped and used to train the classifer in addition to the benchmark datasets ([Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140) and [IMDB reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)) are also provided.
